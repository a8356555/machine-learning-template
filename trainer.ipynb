{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations    \n",
    "import sys\n",
    "from utils_ml import (StatisticalDataNormalizer, Trainer, MetricCalculator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare\n",
    "\n",
    "df_path = ''\n",
    "df = pd.read_csv(df_path)\n",
    "label_col = ''\n",
    "all_seed_list = [666, 777, 888, 999, 111]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = -1\n",
    "n_estimators = 100\n",
    "\n",
    "trainer = Trainer(df, all_seed_list, label_col=label_col, enable_shap_plot=True, debug=False, \n",
    "                  model_name_list=['LR', 'LGBM'], max_depth=max_depth, n_estimators=n_estimators)\n",
    "df_outputs, all_model_dict, df_feat_importances = trainer.cross_validate()\n",
    "\n",
    "metric_calculator = MetricCalculator(all_model_dict, df_outputs, label_col=label_col)\n",
    "df_metrics = metric_calculator.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.groupby(['model', 'phase']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "df_feat_importances.groupby('model').mean().transpose().sort_values('LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model_trained_with_all_data(model_name='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = df_outputs\n",
    "pred_col = ''\n",
    "df['pred'] = df[pred_col]\n",
    "df['gt'] = df[label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df['pred']\n",
    "data = []\n",
    "x = []\n",
    "y = []\n",
    "for lower in np.arange(0, 1, 0.1):\n",
    "    upper = lower + 0.1\n",
    "    x.append(f'{lower:.1f}')\n",
    "    y.append(predictions[(predictions>=lower)&(predictions<upper)].shape[0]/predictions.shape[0])\n",
    "\n",
    "sns.barplot(x, y)\n",
    "plt.title('Reliability Diagrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "class SigmoidCalibrator:\n",
    "    def __init__(self, prob_pred, prob_true):\n",
    "        prob_pred, prob_true = self._filter_out_of_domain(prob_pred, prob_true)\n",
    "        prob_true = np.log(prob_true / (1 - prob_true))\n",
    "        self.regressor = LinearRegression().fit(\n",
    "            prob_pred.reshape(-1, 1), prob_true.reshape(-1, 1)\n",
    "        )\n",
    "\n",
    "    def calibrate(self, probabilities):\n",
    "        return 1 / (1 + np.exp(-self.regressor.predict(probabilities.reshape(-1, 1)).flatten()))\n",
    "\n",
    "    def _filter_out_of_domain(self, prob_pred, prob_true):\n",
    "        filtered = list(zip(*[p for p in zip(prob_pred, prob_true) if 0 < p[1] < 1]))\n",
    "        return np.array(filtered)\n",
    "\n",
    "\n",
    "class IsotonicCalibrator:\n",
    "    def __init__(self, prob_pred, prob_true):\n",
    "        self.regressor = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "        self.regressor.fit(prob_pred, prob_true)\n",
    "\n",
    "    def calibrate(self, probabilities):\n",
    "        return self.regressor.predict(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrators = {}\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(df['gt'], predictions, n_bins=10)\n",
    "\n",
    "calibrators[\"sigmoid\"] = SigmoidCalibrator(prob_pred, prob_true)\n",
    "calibrators[\"isotonic\"] = IsotonicCalibrator(prob_pred, prob_true)\n",
    "\n",
    "\n",
    "for k, v in calibrators.items():\n",
    "    calibrated_preds = v.calibrate(np.array(predictions))\n",
    "    prob_true, prob_pred = calibration_curve(df['gt'], calibrated_preds, n_bins=10)\n",
    "    plt.plot(prob_true)\n",
    "    plt.plot(prob_pred)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (timelapse-ai)",
   "language": "python",
   "name": "pycharm-3425131e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (default, Aug 31 2020, 12:42:55) \n[GCC 7.3.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
